{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "model_name = \"tiiuae/falcon-7b-instruct\" \n",
    "\n",
    "print(\"Loading model...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16 if device == \"cuda\" else torch.float32\n",
    ").to(device)\n",
    "print(\"Model loaded.\")\n",
    "\n",
    "# BDI-II symptom list\n",
    "bdi_symptoms = [\n",
    "    \"sadness\", \"pessimism\", \"past failure\", \"loss of pleasure\", \"guilty feelings\",\n",
    "    \"punishment feelings\", \"self-dislike\", \"self-criticalness\", \"suicidal thoughts or wishes\",\n",
    "    \"crying\", \"agitation\", \"loss of interest\", \"indecisiveness\", \"worthlessness\",\n",
    "    \"loss of energy\", \"changes in sleeping pattern\", \"irritability\", \"changes in appetite\",\n",
    "    \"concentration difficulty\", \"tiredness or fatigue\", \"loss of interest in sex\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file2write=open(\"infer_out.txt\",'w')\n",
    "\n",
    "def analyze_conversation_bdi_from_file(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        conversation_text = json.load(f)[\"conversation\"]\n",
    "\n",
    "    msgs = []\n",
    "    i = 0\n",
    "    hau = \"\"\n",
    "    for inst in conversation_text:\n",
    "        if i == 0 and \"Example\" not in inst[\"message\"]:\n",
    "            continue\n",
    "        elif i == 0:\n",
    "            i += 1\n",
    "            continue\n",
    "        \n",
    "        if inst[\"role\"] == \"user\":\n",
    "            hau = inst[\"message\"]\n",
    "        if inst[\"role\"] != \"user\":\n",
    "            hau += inst[\"message\"]\n",
    "            msgs.append(hau)\n",
    "\n",
    "    print(msgs)\n",
    "    print(\"--------------------\")\n",
    "\n",
    "    for sent in msgs:\n",
    "        prompt = f\"\"\"\n",
    "        You are a compassionate mental health assistant. Analyze the following message and assess the severity of the most relevant depression symptom, rating the relevance of the symptom on a scale from 0 (irrelevant) to 63 (very relevant). Output only the symptom and the score.\n",
    "These are the symptoms: {symptom_list}. \n",
    "Here is the message: {sent}.\n",
    "        \"\"\"\n",
    "\n",
    "        inputs = tokenizer(prompt.strip(), return_tensors=\"pt\", truncation=True, max_length=1024)\n",
    "        outputs = model.generate(**inputs, max_new_tokens=256)\n",
    "        decoded = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "        file2write.write(decoded)\n",
    "    \n",
    "    return decoded\n",
    "\n",
    "import glob\n",
    "for file_path in glob.glob(f\"./*.json\"):\n",
    "    if \"results\" in file_path:\n",
    "        file2write.write(file_path)\n",
    "        continue\n",
    "    print(file_path)\n",
    "    #with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    analyze_conversation_bdi_from_file(file_path)\n",
    "\n",
    "file2write.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "# File containing all outputs\n",
    "FILENAME = 'infer_out.txt'\n",
    "\n",
    "# Pattern to identify new persona block\n",
    "persona_pattern = re.compile(r'\\./interactions_run4_(\\w+)\\.json')\n",
    "\n",
    "# Pattern to extract symptom and score from output\n",
    "symptom_score_pattern = re.compile(r'\"([^\"]+)\".*?(\\d{1,2})')\n",
    "\n",
    "# Dictionary to hold data per persona\n",
    "person_data = defaultdict(list)\n",
    "\n",
    "# Read and process the file\n",
    "with open(FILENAME, 'r') as f:\n",
    "    current_persona = None\n",
    "    for line in f:\n",
    "        # Check for a new persona section\n",
    "        persona_match = persona_pattern.search(line)\n",
    "        if persona_match:\n",
    "            current_persona = persona_match.group(1).capitalize()\n",
    "            continue\n",
    "\n",
    "        if current_persona:\n",
    "            match = symptom_score_pattern.search(line)\n",
    "            if match:\n",
    "                symptom, score = match.groups()\n",
    "                symptom = symptom.strip().replace(',', '').replace('.', '').capitalize()\n",
    "                score = int(score) if score is not None else None\n",
    "                if score is not None and score != 0:\n",
    "                    person_data[current_persona].append((symptom, score))\n",
    "                else:\n",
    "                    # Try to find a symptom\n",
    "                    symptom_match = re.search(r'\"([^\"]+)\"', line)\n",
    "                    if symptom_match:\n",
    "                        symptom = symptom_match.group(1).strip().replace(',', '').replace('.', '').capitalize()\n",
    "                        # Try to infer score from relevance\n",
    "                        if 'very relevant' in line.lower():\n",
    "                            score = 60\n",
    "                        elif 'relevant' in line.lower():\n",
    "                            score = 45\n",
    "                        elif 'somewhat relevant' in line.lower():\n",
    "                            score = 30\n",
    "                        elif 'a little relevant' in line.lower():\n",
    "                            score = 15\n",
    "                        else:\n",
    "                            print(f\"[Manual check needed] {line.strip()}\")\n",
    "                            continue\n",
    "                        person_data[current_persona].append((symptom, score))\n",
    "            else:\n",
    "                # Try to find a symptom\n",
    "                symptom_match = re.search(r'\"([^\"]+)\"', line)\n",
    "                if symptom_match:\n",
    "                    symptom = symptom_match.group(1).strip().replace(',', '').replace('.', '').capitalize()\n",
    "                    # Try to infer score from relevance\n",
    "                    if \"Here is the message\" in line or \"These are the symptoms\" in line:\n",
    "                        continue\n",
    "                    if 'very relevant' in line.lower():\n",
    "                        score = 60\n",
    "                    elif 'moderately relevant' in line.lower() or \"significant contributor\" in line.lower():\n",
    "                        score = 45\n",
    "                    elif 'central' in line.lower():\n",
    "                        score = 30\n",
    "                    elif 'likely contributing' in line.lower() or \"likely reflects\" in line.lower():\n",
    "                        score = 15\n",
    "                    else:\n",
    "                        print(f\"[Manual check needed] {line.strip()}\")\n",
    "                        continue\n",
    "                    person_data[current_persona].append((symptom, score))\n",
    "\n",
    "#print(person_data)\n",
    "\n",
    "# Build results\n",
    "results = []\n",
    "for persona, entries in person_data.items():\n",
    "    symptoms = defaultdict(list)\n",
    "    for symptom, score in entries:\n",
    "        symptoms[symptom].append(score)\n",
    "    print(persona)\n",
    "\n",
    "    # Use max score per symptom instead of average\n",
    "    max_symptoms = {sym: max(scores) for sym, scores in symptoms.items()}\n",
    "    print(max_symptoms)\n",
    "\n",
    "    # Sort symptoms by average score to get top 4\n",
    "    top_symptoms_sorted = sorted(max_symptoms.items(), key=lambda x: x[1], reverse=True)[:4]\n",
    "    print(top_symptoms_sorted)\n",
    "\n",
    "    # Calculate BDI score as mean of all 21 symptoms\n",
    "    total_symptom_scores = [scores for scores in max_symptoms.values()]\n",
    "    bdi_score = round(sum(total_symptom_scores) / 21) if total_symptom_scores else 0\n",
    "\n",
    "    results.append({\n",
    "        \"LLM\": persona,\n",
    "        \"bdi-score\": bdi_score,\n",
    "        \"key-symptoms\": [sym for sym, _ in top_symptoms_sorted]\n",
    "    })\n",
    "\n",
    "# Output the result as JSON\n",
    "print(json.dumps(results, indent=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
